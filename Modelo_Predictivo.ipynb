{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efe1aae6-8449-4536-84b6-f6662ad3678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Mean Absolute Error): 171.8639578337584\n",
      "MSE (Mean Squared Error): 162531.30204607785\n",
      "R² (R-squared): 0.9047470087167826\n"
     ]
    }
   ],
   "source": [
    "##REGRESION LINEAL##\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cargar el DataFrame desde el archivo CSV\n",
    "df = pd.read_csv('C:/Proyecto_Final/DataSetFinal.csv')\n",
    "\n",
    "# 1. División de Datos\n",
    "X = df[['Wind Speed (m/s)', 'Theoretical_Power_Curve (kW)']]\n",
    "y = df['LV ActivePower (kW)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Ingeniería de Características (Ejemplo: Características Polinómicas)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# 3. Entrenamiento del Modelo (Ejemplo: Regresión Lineal)\n",
    "model = LinearRegression()  # Aquí usé LinearRegression en lugar de Ridge\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# 4. Predicción en el Conjunto de Prueba\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# 5. Evaluación del Modelo\n",
    "mae_rl = mean_absolute_error(y_test, y_pred)\n",
    "mse_rl = mean_squared_error(y_test, y_pred)\n",
    "r2_rl = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE (Mean Absolute Error): {mae_rl}')\n",
    "print(f'MSE (Mean Squared Error): {mse_rl}')\n",
    "print(f'R² (R-squared): {r2_rl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cff76b42-bf70-4541-b426-e2de80cbaf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Mean Absolute Error): 201.29468737961244\n",
      "MSE (Mean Squared Error): 227851.12887805814\n",
      "R² (R-squared): 0.8664657126370652\n"
     ]
    }
   ],
   "source": [
    "##RANDOM FOREST##\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Volver a cargar el dataset\n",
    "df = pd.read_csv(\"C:/Proyecto_Final/DataSetFinal.csv\")\n",
    "\n",
    "# Definir variables predictoras y objetivo\n",
    "X = df[['Wind Speed (m/s)', 'Theoretical_Power_Curve (kW)']]  # Variables predictoras\n",
    "y = df['LV ActivePower (kW)']  # Variable objetivo\n",
    "\n",
    "# Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'MAE (Mean Absolute Error): {mae_rf}')\n",
    "print(f'MSE (Mean Squared Error): {mse_rf}')\n",
    "print(f'R² (R-squared): {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dee3d381-c063-4330-92ba-0cfdbf648f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [17:02<00:00, 24.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 40424, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1311.361866\n",
      "                               Adjusted R-Squared  R-Squared    RMSE  \\\n",
      "Model                                                                  \n",
      "GaussianProcessRegressor                     0.91       0.91  399.02   \n",
      "GradientBoostingRegressor                    0.91       0.91  399.93   \n",
      "HistGradientBoostingRegressor                0.91       0.91  400.08   \n",
      "XGBRegressor                                 0.91       0.91  400.33   \n",
      "LGBMRegressor                                0.91       0.91  400.48   \n",
      "MLPRegressor                                 0.90       0.90  405.56   \n",
      "SVR                                          0.90       0.90  413.32   \n",
      "LassoLars                                    0.90       0.90  413.55   \n",
      "LassoCV                                      0.90       0.90  413.55   \n",
      "Lasso                                        0.90       0.90  413.55   \n",
      "LassoLarsIC                                  0.90       0.90  413.56   \n",
      "Lars                                         0.90       0.90  413.56   \n",
      "LassoLarsCV                                  0.90       0.90  413.56   \n",
      "LarsCV                                       0.90       0.90  413.56   \n",
      "LinearRegression                             0.90       0.90  413.56   \n",
      "OrthogonalMatchingPursuitCV                  0.90       0.90  413.56   \n",
      "TransformedTargetRegressor                   0.90       0.90  413.56   \n",
      "RidgeCV                                      0.90       0.90  413.56   \n",
      "BayesianRidge                                0.90       0.90  413.56   \n",
      "Ridge                                        0.90       0.90  413.56   \n",
      "NuSVR                                        0.90       0.90  413.56   \n",
      "SGDRegressor                                 0.90       0.90  414.09   \n",
      "OrthogonalMatchingPursuit                    0.90       0.90  417.87   \n",
      "AdaBoostRegressor                            0.90       0.90  418.02   \n",
      "LinearSVR                                    0.90       0.90  422.36   \n",
      "RANSACRegressor                              0.89       0.89  424.35   \n",
      "PassiveAggressiveRegressor                   0.89       0.89  426.13   \n",
      "HuberRegressor                               0.89       0.89  426.19   \n",
      "KNeighborsRegressor                          0.89       0.89  434.89   \n",
      "RandomForestRegressor                        0.87       0.87  477.28   \n",
      "BaggingRegressor                             0.86       0.86  486.56   \n",
      "ElasticNet                                   0.85       0.85  500.28   \n",
      "ExtraTreesRegressor                          0.85       0.85  505.85   \n",
      "ExtraTreeRegressor                           0.83       0.83  543.90   \n",
      "DecisionTreeRegressor                        0.82       0.82  556.76   \n",
      "TweedieRegressor                             0.79       0.79  602.50   \n",
      "ElasticNetCV                                 0.75       0.75  648.91   \n",
      "DummyRegressor                              -0.00      -0.00 1306.39   \n",
      "KernelRidge                                 -0.10      -0.10 1369.99   \n",
      "QuantileRegressor                           -0.13      -0.13 1385.94   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "GaussianProcessRegressor           546.36  \n",
      "GradientBoostingRegressor            4.11  \n",
      "HistGradientBoostingRegressor        0.27  \n",
      "XGBRegressor                         0.28  \n",
      "LGBMRegressor                        0.12  \n",
      "MLPRegressor                        19.87  \n",
      "SVR                                102.70  \n",
      "LassoLars                            0.01  \n",
      "LassoCV                              0.24  \n",
      "Lasso                                0.03  \n",
      "LassoLarsIC                          0.02  \n",
      "Lars                                 0.04  \n",
      "LassoLarsCV                          0.03  \n",
      "LarsCV                               0.05  \n",
      "LinearRegression                     0.01  \n",
      "OrthogonalMatchingPursuitCV          0.02  \n",
      "TransformedTargetRegressor           0.01  \n",
      "RidgeCV                              0.02  \n",
      "BayesianRidge                        0.01  \n",
      "Ridge                                0.01  \n",
      "NuSVR                              113.55  \n",
      "SGDRegressor                         0.04  \n",
      "OrthogonalMatchingPursuit            0.01  \n",
      "AdaBoostRegressor                    0.27  \n",
      "LinearSVR                            0.02  \n",
      "RANSACRegressor                      0.05  \n",
      "PassiveAggressiveRegressor           0.03  \n",
      "HuberRegressor                       0.09  \n",
      "KNeighborsRegressor                  0.05  \n",
      "RandomForestRegressor               11.17  \n",
      "BaggingRegressor                     1.18  \n",
      "ElasticNet                           0.01  \n",
      "ExtraTreesRegressor                  4.05  \n",
      "ExtraTreeRegressor                   0.05  \n",
      "DecisionTreeRegressor                0.19  \n",
      "TweedieRegressor                     0.01  \n",
      "ElasticNetCV                         0.21  \n",
      "DummyRegressor                       0.01  \n",
      "KernelRidge                        175.84  \n",
      "QuantileRegressor                   41.83  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##LAZYPREDICT##\n",
    "\n",
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(\"C:/Proyecto_Final/DataSetFinal.csv\")\n",
    "\n",
    "# Definir variables predictoras y objetivo\n",
    "X = df[['Wind Speed (m/s)', 'Theoretical_Power_Curve (kW)']]\n",
    "y = df['LV ActivePower (kW)']\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar LazyRegressor\n",
    "lazy_regressor = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = lazy_regressor.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Mostrar los resultados ordenados por R²\n",
    "print(models.sort_values(by=\"R-Squared\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "715d7096-d365-4f82-a4b5-827855b9f43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 40424, number of used features: 2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Start training from score 1311.361866\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "MAE (Mean Absolute Error): 166.33198549227842\n",
      "MSE (Mean Squared Error): 159868.8876451902\n",
      "R² (R-squared): 0.9063073416036019\n"
     ]
    }
   ],
   "source": [
    "##LIGHTGBM ###  MODELO ESCOGIDO ##\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(\"C:/Proyecto_Final/DataSetFinal.csv\")\n",
    "\n",
    "# Reemplazar espacios en los nombres de las columnas por guiones bajos\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "# Definir variables predictoras y objetivo\n",
    "X = df[['Wind_Speed_(m/s)', 'Theoretical_Power_Curve_(kW)']]  # Variables predictoras\n",
    "y = df['LV_ActivePower_(kW)']  # Variable objetivo\n",
    "\n",
    "# Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo LGBMRegressor\n",
    "lgb_model = LGBMRegressor(\n",
    "    objective='regression',\n",
    "    metric='rmse',  # Root Mean Squared Error\n",
    "    num_leaves=31,  # Número de hojas en cada árbol\n",
    "    learning_rate=0.05,\n",
    "    feature_fraction=0.9,  # Fracción de características a considerar para cada iteración\n",
    "    n_estimators=100  # Número de estimadores (máximos árboles)\n",
    ")\n",
    "\n",
    "# Entrenar el modelo LightGBM sin verbose\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],  # Especificar el conjunto de validación\n",
    "    eval_metric='rmse'  # Usar RMSE como métrica de evaluación\n",
    ")\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "# Imprimir los resultados de evaluación\n",
    "print(f'MAE (Mean Absolute Error): {mae_lgb}')\n",
    "print(f'MSE (Mean Squared Error): {mse_lgb}')\n",
    "print(f'R² (R-squared): {r2_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5630a-5f85-4d0a-acf2-dba40dab6549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
